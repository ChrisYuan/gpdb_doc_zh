<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_fj5_b1x_r4">
  <title>装载数据</title>
  <shortdesc>本节描述了将数据装载到Greenplum数据库的不同方式。</shortdesc>
  <topic id="topic_tmf_t2t_bp">
    <title>带列值的INSERT语句</title>
    <body>
      <p>带有值的单个<codeph>INSERT</codeph>语句会向表中加入一行。这个行会流过master并且被分布到一个segment上。
        这是最慢的方法并且不适合装载大量数据。</p>
    </body>
  </topic>
  <topic id="topic_oqb_y2t_bp">
    <title>COPY语句</title>
    <body>
      <p>PostgreSQL的<codeph>COPY</codeph>语句从外部文件拷贝数据到数据表中。它比<codeph>INSERT</codeph>
        语句插入多行的效率更高，但是行仍需流过master。所有数据都在一个命令中被拷贝，它并不是一种并行处理。</p>
      <p><codeph>COPY</codeph>命令的数据输入来自于一个文件或者标准输入。例如：
        <codeblock>COPY table FROM '/data/mydata.csv' WITH CSV HEADER;</codeblock>
        使用<codeph>COPY</codeph>适合于增加相对较小的数据集合（例如多达上万行的维度表）或者一次性数据装载。</p>
      <p>在编写脚本处理装载少于1万行的少量数据时使用<codeph>COPY</codeph>。</p>
      <p>因为COPY是一个单一命令，在使用这种方法填充表时没有必要禁用自动提交。</p>
      <p>使用者可以运行多个并发的<codeph>COPY</codeph>命令以提高性能。</p>
    </body>
  </topic>
  <topic id="topic_kgp_z2t_bp">
    <title>外部表</title>
    <body>
      <p>外部表提供了对Greenplum数据库之外的数据来源的访问。可以用<codeph>SELECT</codeph>语句访问它们，外部表
        通常被用于抽取、装载、转换（ELT）模式，这是一种抽取、转换、装载（ETL）模式的变种，这种模式可以利用
        Greenplum数据库的快速并行数据装载能力。</p>
      <p>通过ETL，数据被从其来源抽取，在数据库外部使用外部转换工具（Informatica或者Datastage）转换，然后
        被装载到数据库中。</p>
      <p>通过ELT，Greenplum外部表提供对外部来源中数据的访问，外部来源可以是只读文件（例如文本、CSV或者XML文件）、
        Web服务器、Hadoop文件系统、可执行的OS程序或者Greenplum <codeph>gpfdist</codeph>文件服务器，这些在
        下一节中描述。外部表支持选择、排序和连接这样的SQL操作，这样数据可以被同时装载和转换，或者被装载到一个
        <i>装载表</i>并且在数据库内被转换成目标表。</p>
      <p>外部表使用<codeph>CREATE EXTERNAL TABLE</codeph>语句定义，该语句有一个<codeph>LOCATION</codeph>
        子句定义数据的位置以及一个<codeph>FORMAT</codeph>子句定义源数据的格式，这样系统才能够解析输入数据。
        文件使用<codeph>file://</codeph>协议，并且文件必须位于一台segment主机上由Greenplum超级用户可访问
        的位置。数据可以被分散在segment主机上，并且每台主机上的每个主segment有不超过一个文件。<codeph>LOCATION</codeph>
        子句中列出的文件的数量是将并行读取该外部表的segment的数量。</p>
    </body>
  </topic>
  <topic id="topic_x2l_bft_bp">
    <title>使用Gpfdist外部表</title>
    <body>
      <p>装载大型事实表的最快方式是使用基于<codeph>gpdist</codeph>的外部表。<codeph>gpfdist</codeph>
        是一个使用HTTP协议的文件服务器程序，它以并行的方式向Greenplum数据库的segment供应外部数据文件。
        一个<codeph>gpfdist</codeph>实例每秒能供应200MB并且很多<codeph>gpfdist</codeph>进程可以
        同时运行，每一个供应要被装载的数据的一部分。当使用者用<codeph>INSERT INTO &lt;table> SELECT * FROM &lt;external_table></codeph>
        这样的语句开始装载时，<codeph>INSERT</codeph>语句会被master解析并且分布给主segment。segment
        连接到<codeph>gpfdist</codeph>服务器并且并行检索数据，解析并验证数据，从分布键数据计算一个哈希值
        并且基于哈希键把行发送给它的目标segment。每个<codeph>gpfdist</codeph>实例默认将接受最多64个
        来自segment的连接。通过让更多的segment和<codeph>gpfdist</codeph>服务器参与到装载处理中，可以
        以非常高的速度进行数据装载。</p>
      <p>在使用<codeph>gpfdist</codeph>数量达到配置参数<codeph>gp_external_max_segments</codeph>
        的最大值时，主segment会并行访问外部文件。在优化<codeph>gpfdist</codeph>的性能时，随着
        segment的数量增加会最大化并行性。在尽可能多的ETL节点上均匀地散布数据。将非常大型的数据文件
        分解成相等的部分，并且把数据分散在尽可能多的文件系统上。</p>
      <p>在每个文件系统上运行两个<codeph>gpfdist</codeph>实例。在装载数据时，<codeph>gpfdist</codeph>
        在segment节点上容易变成CPU密集型的操作。举个例子，如果有八个机架的segment节点，在segment上就有大量
        可用的CPU来驱动更多的<codeph>gpfdist</codeph>进程。在尽可能多的接口上运行<codeph>gpfdist</codeph>。
        要注意绑定网卡并且确保启动足够的<codeph>gpfdist</codeph>实例配合它们一起工作。</p>
      <p>有必要在所有这些资源上保持工作处于均衡状态。装载的速度与最慢的节点相同。装载文件布局上的倾斜将导致
        整体装载受制于资源瓶颈。</p>
      <p><codeph>gp_external_max_segs</codeph>配置参数控制每个<codeph>gpfdist</codeph>进程能服务的
        segment数量。默认值是64。使用者可以在saster上的<codeph>postgresql.conf</codeph>配置文件中设置
        一个不同的值。总是保持<codeph>gp_external_max_segs</codeph>和<codeph>gpfdist</codeph>进程的
        数量为一个偶因子，也就是说<codeph>gp_external_max_segs</codeph>值应该是<codeph>gpfdist</codeph>
        进程数的倍数。例如，如果有12个segment和4个<codeph>gpfdist</codeph>进程，规划器会按照下面的方式
        循环分配segment连接：
        <screen>Segment 1  - gpfdist 1 
Segment 2  - gpfdist 2 
Segment 3  - gpfdist 3 
Segment 4  - gpfdist 4 
Segment 5  - gpfdist 1 
Segment 6  - gpfdist 2 
Segment 7  - gpfdist 3 
Segment 8  - gpfdist 4 
Segment 9  - gpfdist 1 
Segment 10 - gpfdist 2 
Segment 11 - gpfdist 3 
Segment 12 - gpfdist 4</screen></p>
      <p>在装载到已有表之前删除索引，并且在装载之后重建索引。在装载完数据后重新创建索引比装载每行时增量更新
        索引更快。</p>
      <p>装载后在表上运行<codeph>ANALYZE</codeph>。在装载期间通过设置<codeph>gp_autostats_mode</codeph>
        为<codeph>NONE</codeph>来禁用自动统计信息收集。在装载出错后运行<codeph>VACUUM</codeph>来回收空间。</p>
      <p>对重度分区的列存表执行少量高频的数据装载可能会对系统有很大影响，因为在每个时间间隔内被访问的物理文件会很多。</p>
    </body>
  </topic>
  <topic id="topic_xyt_cft_bp">
    <title>Gpload</title>
    <body>
      <p><codeph>gpload</codeph>是一种数据装载工具，它扮演着Greenplum外部表并行装载特性的接口的角色。
        </p>
      <p>要当心对<codeph>gpload</codeph>的使用，因为它会创建并且删除外部表，从而可能会导致系统目录膨胀。
        可转而使用<codeph>gpfdist</codeph>，因为它能提供最好的性能。</p>
      <p><codeph>gpload</codeph>使用定义在一个YAML格式的控制文件中的规范来执行一次装载。它会执行下列操作：
        <ul id="ul_zrl_dnp_y4">
          <li>调用<codeph>gpfdist</codeph>进程</li>
          <li>基于定义的源数据创建一个临时的外部表定义</li>
          <li>执行<codeph>INSERT</codeph>、<codeph>UPDATE</codeph>或者<codeph>MERGE</codeph>操作
            将源数据载入数据库中的目标表</li>
          <li>删除临时外部表</li>
          <li>清除<codeph>gpfdist</codeph>进程</li>
        </ul></p>
      <p>装载会在单个事务中完成。</p>
    </body>
  </topic>
  <topic id="topic_ryr_2ft_bp">
    <title>最佳实践</title>
    <body>
      <ul id="ul_kvl_jvs_x4">
        <li>在装载数据之前删掉现有表上的任何索引，并且在装载之后重建那些索引。新创建索引比装载每行时
          增量更新索引更快。</li>
        <li>在装载期间通过将<codeph>gp_autostats_mode</codeph>配置参数设置为<codeph>NONE</codeph>
          禁用自动统计信息收集。</li>
        <li>外部表并非为频繁访问或者ad hoc访问而设计。</li>
        <li>外部表没有统计信息来告知优化器。可以用下面这样的语句在<codeph>pg_class</codeph>系统目录中为
          外部表设置粗略的行数和磁盘页数估计：
          <codeblock>UPDATE pg_class SET reltuples=400000, relpages=400
WHERE relname='myexttable';</codeblock></li>
        <li>在使用<codeph>gpfdist</codeph>时，通过为ETL服务器上的每一块NIC运行一个<codeph>gpfdist</codeph>
          实例以最大化网络带宽。在<codeph>gpfdist</codeph>实例之间均匀地划分源数据。</li>
        <li>在使用<codeph>gpload</codeph>时，在资源允许的情况下同时运行尽可能多的<codeph>gpload</codeph>
          实例。利用可用的CPU、内存和网络资源以增加能从ETL服务器传输到Greenplum数据库的数据量。</li>
        <li>使用<codeph>COPY</codeph>语句的<codeph>SEGMENT REJECT LIMIT</codeph>子句设置在
          <codeph>COPY FROM</codeph>命令被中止之前可以出现错误的行的百分数限制。这个拒绝限制是针对每个
          segment的，当任意一个segment超过该限制时，命令将被中止且不会有行被增加。使用<codeph>LOG ERRORS</codeph>
          子句可以保存错误行。如果有一行在格式上有错误&#8212;例如缺少值或者有多余的值，或者数据类型不对&#8212;
          Greenplum数据库会在内部存储错误信息和行。使用内建SQL函数<codeph>gp_read_error_log()</codeph>
          可以访问这种存储下来的信息。</li>
        <li>如果装载出现错误，在该表上运行<codeph>VACUUM</codeph>以恢复空间。</li>
        <li>在用户装载数据到表中后，在堆表（包括系统目录）上运行<codeph>VACUUM</codeph>，并且在所有的表上运行
          <codeph>ANALYZE</codeph>。没有必要在追加优化表上运行<codeph>VACUUM</codeph>。如果表已经被分过区，
          用户可以只清理和分析受数据装载影响的分区。这些步骤会清除来自于被中止的装载、删除或者更新中的行并且为表
          更新统计信息。</li>
        <li>在装载大量数据之后重新检查表中的segment倾斜。用户可以使用下面这样的查询来检查倾斜：
          <codeblock outputclass="language-sql">SELECT gp_segment_id, count(*) 
FROM <i>schema.table</i> 
GROUP BY gp_segment_id ORDER BY 2;</codeblock></li>
        <li><codeph>gpfdist</codeph>默认假定最大记录尺寸为32K。要装载大于32K的数据记录，用户必须通过在
          <codeph>gpfdist</codeph>命令行上指定<codeph>-m &lt;<i>bytes</i></codeph>选项来增加最大行
          尺寸参数。如果用户使用的是<codeph>gpload</codeph>，在<codeph>gpload</codeph>控制文件中设置
          <codeph>MAX_LINE_LENGTH</codeph>参数。
          <note>与Informatica Power Exchange的集成当前被限制为默认的32K记录长度。</note></li>
      </ul>
      <section>
        <title>额外信息</title>
        <p>使用<codeph>gpfdist</codeph>和<codeph>gpload</codeph>装载数据的详细指导步骤请见
          <i>Greenplum数据库参考指南</i>。</p>
      </section>
    </body>
  </topic>
</topic>
