<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_hhc_z5w_r4">
  <title>采用资源组管理内存和资源</title>
  <shortdesc>采用资源组管理Greenplum数据库资源。</shortdesc>
  <body>
    <p>在Greenplum数据库集群中，内存、CPU和并发事务管理对性能影响非常巨大。资源组是Greenplum数据库
      提供的用来强制限制内存、CPU和并发事务的全新资源管理模式。</p>
    <ul id="ul_agm_sbl_zt">
      <li>
        <xref href="#topic_hhc_z5w_r4/section_r52_rbl_zt" format="dita"/>
      </li>
      <li>
        <xref href="#topic_hhc_z5w_r4/configuring_rg" format="dita"/>
      </li>
      <li>
        <xref href="#topic_hhc_z5w_r4/section113x" format="dita"/>
      </li>
      <li>
        <xref href="#topic_hhc_z5w_r4/section177x" format="dita"/>
      </li>
    </ul>
    <section id="section_r52_rbl_zt">
      <title>配置Greenplum数据库内存</title>
      <p>一直增加系统内存是不可能的，客户可以通过配置资源组来管理可预期的工作负载，这样能够避免
        内存溢出的情况发生。</p>
      <p>以下操作系统和Greenplum数据库内存设置对采用资源组来管理日常工作是非常有用的：</p>
      <ul id="ul_xv2_phn_1s">
        <li>
          <b>vm.overcommit_memory</b>
          <p>该Linux内核参数在<codeph>/etc/sysctl.conf</codeph>文件中设置，用来指定操作系统
            分配给系统进程使用多少内存的方法。<codeph>vm.overcommit_memory</codeph>在
            Greenplum数据库所在的机器上必须设置为2。
          </p>
        </li>
        <li>
          <b>vm.overcommit_ratio</b>
          <p>该Linux内核参数在<codeph>/etc/sysctl.conf</codeph>文件中设置，用来执行应用进程
            可以使用的内存百分比；剩余的内存留给操作系统。操作系统默认值（Red Hat上默认是50）对于
            部署Greenplum数据库集群基于资源组的管理方式是一个不错的初始值。如果感觉内存利用率太低，
            便可以提高该值；如果内存或交换分区使用太高，就减少该设置。</p>
        </li>
        <li>
          <b>gp_resource_group_memory_limit</b>
          <p>系统分配给Greenplum数据库的内存百分比。默认值为.7(70%)。</p> 
        </li>
        <li>
          <b>gp_workfile_limit_files_per_query</b>
          <p>设置<codeph>gp_workfile_limit_files_per_query</codeph>以限制每个查询允许使用的临时溢出文件
            （工作文件）的最大数量。当查询要求的内存比它能分配的更多时，它将创建溢出文件。当上述限制被超过时，查询
            会被中止。默认值为零，允许无限多的溢出文件并且可能会填满文件系统。</p>
        </li>
        <li>
          <p>
            <b>gp_workfile_compression</b>
          </p>
          <p>如果有很多溢出文件，则设置<codeph>gp_workfile_compression</codeph>来压缩这些溢出文件。
            压缩溢出文件可能有助于避免IO操作导致磁盘子系统过载。</p>
        </li>
      </ul>
      <p>其他考虑因素：</p>
      <ul id="ul_xv2_phn_2z">
        <li>不要启用操作系统大页配置。</li>
        <li>当您配置资源组内存时，提前考虑出现segment实例或segment主机宕机时，镜像segment变成
          主segment对系统内存的占用。
        </li>
      </ul>
    </section>
    <section id="configuring_rg">
      <title>配置资源组</title>
      <p>Greenplum数据库资源组能提供管理集群负载的强有力手段。当您在系统中配置资源组时，考虑以下常规指导方法：</p>
      <ul id="ul_svy_b3n_1s">
        <li>任何具有<codeph>SUPERUSER</codeph>权限的用户提交的事务都在默认资源组
          <codeph>admin_group</codeph>下运行。在调度和运行任何Greenplum管理工具
          时都要牢记这一点。</li>
        <li>确保为每一个非管理员用户分配一个用户组。如果不给用户分配资源组，那么该用户
          提交的查询会被默认资源组<codeph>default_group</codeph>处理。</li>
        <li>采用资源组参数<codeph>CONCURRENCY</codeph>来限制某个资源组可以并发
          运行的活动查询的数量。</li>
        <li>采用<codeph>MEMORY_LIMIT</codeph>和<codeph>MEMORY_SHARED_QUOTA</codeph>参数
          控制运行在资源组中的查询可以申请的最大内存数量。</li>
        <li>Greenplum数据库会将无保留内存（100-（所有资源组<codeph>MEMORY_LIMIT</codeph>总和））
          全部分配给全局共享内存池。该内存本着一视同仁的原则，先到先得。</li>
        <li>基于实时需求和负载的变化来动态调整资源组满足业务要求。</li>
        <li>采用<codeph>gptoolkit</codeph>视图检查资源组使用情况，来监控资源组工作良好。</li>
        <li otherprops="pivotal">Consider using Pivotal Greenplum Command Center
          to create and manage resource groups, and to define the criteria under which
          Command Center dynamically assigns a transaction to a resource group.</li>
      </ul>
    </section>
    <section id="section113x" xml:lang="en">
      <title>低内存查询</title>
      <p><codeph>memory_spill_ratio</codeph>设置为较低值时（例如，在0-2%之间）能够提升低内存要求
        查询的性能。我们可以在每个查询之前让<codeph>memory_spill_ratio</codeph>生效来覆盖系统默认
        设置。例如：
        <codeblock>SET memory_spill_ratio=0;</codeblock></p>
    </section>
    <section id="section177x" xml:lang="en">
      <title>管理工具和admin_group并行</title>
      <p>Greenplum数据库用户<codeph>SUPERUSER</codeph>s的默认资源组是<codeph>admin_group</codeph>。
        <codeph>admin_group</codeph>资源组的默认<codeph>CONCURRENCY</codeph>值为10。</p>
      <p>某些Greenplum数据库管理工具可能会同时使用多个<codeph>CONCURRENCY</codeph>槽，例如
        使用<codeph>gpbackup</codeph>带有<codeph>--jobs</codeph>选项时。如果客户运行的工具
        要求的并发事务数比<codeph>admin_group</codeph>的多，可以考虑临时增加该资源组的
        <codeph>MEMORY_LIMIT</codeph>和<codeph>CONCURRENCY</codeph>，以满足工具的要求，
        但一定要记得在工具执行完后及时将这些设置恢复原样。
        <note>通过修改<codeph>ALTER RESOURCE GROUP</codeph>达到的内存改变并不能立刻影响到正在运行的
          查询。所以尽量选择在维护窗口时间修改资源组参数。</note></p>
    </section>
  </body>
</topic>
