---
title: PXF故障排查
---

<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->


## <a id="pxf-errors"></a>PXF错误
下表描述了使用PXF时可能会遇到的一些错误：

| Error Message                 | Discussion                     |
|-------------------------------|---------------------------------|
| Protocol "pxf" does not exist | **Cause**: pxf扩展名未注册。<br>**Solution**: 按照PXF启用过程中的说明为[Enable Procedure](using_pxf.html#enable-pxf-ext) 为数据库创建（启用）PXF扩展 |
| Invalid URI pxf://\<path-to-data\>: missing options section | **Cause**: `LOCATION` URI配置项不包括配置或其他需要的信息。<br>**Solution**:在URI中提供配置和必需的选项。|
| org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://\<namenode\>:8020/\<path-to-file\> | **Cause**: 在\<path-to-file\>中指定的HDFS文件不存在。<br>**Solution**: 指定现有HDFS文件的路径|
| NoSuchObjectException(message:\<schema\>.\<hivetable\> table not found) | **Cause**: \<schema\>.\<hivetable\>指定的Hive表不存在。<br>**Solution**: 提供存在的Hive表的名称。|
| Failed to connect to \<segment-host\> port 5888: Connection refused (libchurl.c:944)  (\<segment-id\> slice\<N\> \<segment-host\>:40000 pid=\<process-id\>)<br> ... |**Cause**: 在\<segment-host\>主机上PXF未运行。 <br>**Solution**: \<segment-host\>主机上重启PXF|
| *ERROR*: failed to acquire resources on one or more segments<br>*DETAIL*:  could not connect to server: Connection refused<br>&nbsp;&nbsp;&nbsp;&nbsp;Is the server running on host "\<segment-host\>" and accepting<br>&nbsp;&nbsp;&nbsp;&nbsp;TCP/IP connections on port 40000?(seg\<N\> \<segment-host\>:40000) | **Cause**: GPDB集群 \<segment-host\> 节点down |
| org.apache.hadoop.security.AccessControlException: Permission denied: user=<user>, access=READ, inode=&quot;<filepath>&quot;:<user>:<group>:-rw------- | **Cause**: 执行PXF操作的Greenplum数据库用户无权访问基础Hadoop服务（HDFS或Hive）。参阅[Configuring User Impersonation and Proxying](pxfuserimpers.html). |

## <a id="pxf-logging"></a>PXF日志

启用更详细的日志记录可能有助于PXF故障排除工作。 PXF提供了两类消息日志记录：服务级别和客户端级别。

### <a id="pxfsvclogmsg"></a>服务级别日志记录

PXF利用`log4j`进行服务级别的日志记录。PXF-service-related日志消息捕获由`$PXF_CONF/conf/pxf-log4j.properties`文件中的`log4j`控制。默认的PXF日志记录配置会将INFO和更严格的日志记录写入`$PXF_CONF/logs/pxf-service.log`。您可以配置日志记录级别和日志文件位置。

启用`DEBUG`级别时，PXF提供更详细的日志记录。要配置PXF`DEBUG`日志记录并检查输出，请执行以下操作：

1. 登录gpdb集群的master主机

    ``` shell
    $ ssh gpadmin@<gpmaster>
    ```

1. 使用编辑器打开 `$PXF_CONF/conf/pxf-log4j.properties`，取消以下行的注释，保存文件，然后退出编辑器：

    ``` shell
    #log4j.logger.org.greenplum.pxf=DEBUG
    ```

2. 使用 `pxf cluster sync` 命令拷贝更新的文件 `pxf-log4j.properties` 到每个segment主机。例如：

    ``` shell
    gpadmin@gpmaster$ $GPHOME/pxf/bin/pxf cluster sync
    ```

3. 依照[Restarting PXF](cfginitstart_pxf.html#restart_pxf)章节描述，重启gpdb集群的每个segment节点的pxf

4. 现在启用了`DEBUG`级别的日志记录，您可以执行PXF操作。 确保记下时间； 这会将信息定向输出到 `$PXF_CONF/logs/pxf-service.log`中的相关日志。

    ``` shell
    $ date
    Wed Oct  4 09:30:06 MDT 2017
    $ psql -d <dbname>
    ```

4. 创建和查询外部表。例如：

    ``` sql
    dbname=> CREATE EXTERNAL TABLE hdfstest(id int, newid int)
        LOCATION ('pxf://data/dir/hdfsfile?PROFILE=hdfs:text')
        FORMAT 'TEXT' (delimiter='E',');
    dbname=> SELECT * FROM hdfstest;
    <select output>
    ```

5. 最后，从`pxf-service.log`检查/收集日志消息。

**Note**: `DEBUG` 记录非常冗长，并且会对性能产生影响. 在收集了所需的信息之后，请关闭PXF服务的`DEBUG`日志记录。


### <a id="pxfdblogmsg"></a>客户端级别日志记录

数据库级客户端日志记录可以提供对内部PXF服务操作的了解。

在psql会话中将`client_min_messages`服务器配置参数设置为`DEBUG2`，可以在对PXF外部表进行操作期间启用Greenplum数据库及PXF调试消息日志记录。

``` shell
$ psql -d <dbname>
```

``` sql
dbname=# SET client_min_messages=DEBUG2;
dbname=# SELECT * FROM hdfstest;
...
DEBUG2:  churl http header: cell #19: X-GP-URL-HOST: seghost1  (seg0 slice1 127.0.0.1:40000 pid=3981)
CONTEXT:  External table hdfstest
DEBUG2:  churl http header: cell #20: X-GP-URL-PORT: 5888  (seg0 slice1 127.0.0.1:40000 pid=3981)
CONTEXT:  External table hdfstest
DEBUG2:  churl http header: cell #21: X-GP-DATA-DIR: data/dir/hdfsfile  (seg0 slice1 127.0.0.1:40000 pid=3981)
CONTEXT:  External table hdfstest
DEBUG2:  churl http header: cell #22: X-GP-OPTIONS-PROFILE: hdfs:text  (seg0 slice1 127.0.0.1:40000 pid=3981)
CONTEXT:  External table hdfstest
...
```

检查/收集来自stdout的日志消息

**Note**: `DEBUG2`数据库会话日志记录会影响性能。记住，在收集了所需的信息之后，请关闭`DEBUG2`日志记录。

``` sql
dbname=# SET client_min_messages=NOTICE;
```

## <a id="pxf-memcfg"></a>Addressing PXF Memory Issues

Because a single PXF agent (JVM) serves multiple segments on a segment host, the PXF heap size can be a limiting runtime factor. This will be more evident under concurrent workloads and/or queries against large files. You may run into situations where a query will hang or fail due to insufficient memory or the Java garbage collector impacting response times. To avert or remedy these situations, first try increasing the Java maximum heap size or decreasing the Tomcat maximum number of threads, depending upon what works best for your system configuration.

**Note**: The configuration changes described in this topic require modifying config files on *each* segment node in your Greenplum Database cluster. After you perform the updates, be sure to synchronize the PXF configuration to each segment host in the cluster.

You will need to re-apply these configuration changes after any PXF version upgrades.

### <a id="pxf-heapcfg"></a>Increasing the JVM Memory for PXF

Each PXF agent running on a segment host is configured with a default maximum Java heap size of 2GB and an initial heap size of 1GB. If the segment hosts in your Greenplum Database cluster have an ample amount of memory, try increasing the maximum heap size to a value between 3-4GB. Set the initial and maximum heap size to the same value if possible.

Perform the following procedure to increase the heap size for the PXF agent running on each segment host in your Greenplum Database cluster.

1. Log in to your Greenplum Database master node:

    ``` shell
    $ ssh gpadmin@<gpmaster>
    ```

2. Recall the location of the PXF user configuration directory ($PXF_CONF). Edit the `$PXF_CONF/conf/pxf-env.sh` file. For example:

    ``` shell
    gpadmin@gpmaster$ vi $PXF_CONF/conf/pxf-env.sh
    ```

3. Locate the `PXF_JVM_OPTS` setting in the `pxf-env.sh` file, and update the `-Xmx` and/or `-Xms` options to the desired value. For example:

    ``` shell
    PXF_JVM_OPTS="-Xmx3g -Xms3g"
    ```

4. Use the `pxf cluster sync` command to copy the updated `pxf-env.sh` file to each Greenplum Database segment host. For example:

    ``` shell
    gpadmin@gpmaster$ $GPHOME/pxf/bin/pxf cluster sync
    ```

5. Restart PXF on each Greenplum Database segment host as described in [Restarting PXF](cfginitstart_pxf.html#restart_pxf).

### <a id="pxf-threadcfg"></a>Another Option for Resource-Constrained PXF Segment Hosts

If increasing the maximum heap size is not suitable for your Greenplum Database deployment, try decreasing the number of concurrent working threads configured for PXF's underlying Tomcat web application. A decrease in the number of running threads will prevent any PXF node from exhausting its memory, while ensuring that current queries run to completion (albeit a bit slower). Tomcat's default behavior is to queue requests until a thread is free, or the queue is exhausted.

The Tomcat default maximum number of threads is 300. Decrease the maximum number of threads to a value that works optimally for your Greenplum Database deployment. (If you plan to run large workloads on a large number of files in an external Hive data store, specify an even lower value.)

Perform the following procedure to decrease the maximum number of Tomcat threads for the PXF agent running on each segment host in your Greenplum Database deployment.

1. Log in to your Greenplum Database master node:

    ``` shell
    $ ssh gpadmin@<gpmaster>
    ```

2. Edit the `$GPHOME/pxf/pxf-service/conf/server.xml` file. For example:

    ``` shell
    gpadmin@gpmaster$ vi $GPHOME/pxf/pxf-service/conf/server.xml
    ```

3. Locate the `Catalina` `Executor` block and update the `maxThreads` setting to the desired value. For example:

    ``` xml
    <Executor maxThreads="100"
              minSpareThreads="50"
              name="tomcatThreadPool"
              namePrefix="tomcat-http--"/>
    ```

4. Copy the updated `server.xml` file to each Greenplum Database segment host. For example, if `seghostfile` contains a list, one-host-per-line, of the segment hosts in your Greenplum Database cluster:

    ``` shell
    gpadmin@gpmaster$ gpscp -v -f seghostfile $GPHOME/pxf/pxf-service/conf/server.xml =:/usr/local/greenplum-db/pxf/pxf-service/conf/server.xml
    ```

5. Restart PXF on each Greenplum Database segment host as described in [Restarting PXF](cfginitstart_pxf.html#restart_pxf).

## <a id="pxf-timezonecfg"></a>Addressing PXF JDBC Connector Time Zone Errors

You use the PXF JDBC connector to access data stored in an external SQL database. Depending upon the JDBC driver, the driver may return an error if there is a mismatch between the default time zone set for the PXF server and the time zone set for the external SQL database.

For example, if you use the PXF JDBC connector to access an Oracle database with a conflicting time zone, PXF logs an error similar to the following:

``` pre
SEVERE: Servlet.service() for servlet [PXF REST Service] in context with path [/pxf] threw exception
java.io.IOException: ORA-00604: error occurred at recursive SQL level 1
ORA-01882: timezone region not found
```

Should you encounter this error, you can set default time zone option(s) for the PXF server in the `$PXF_CONF/conf/pxf-env.sh` configuration file, `PXF_JVM_OPTS` property setting. For example, to set the time zone:

``` pre
export PXF_JVM_OPTS="<current_settings> -Duser.timezone=America/Chicago"
```

You can use the `PXF_JVM_OPTS` property to set other Java options as well.

As described in previous sections, you must synchronize the updated PXF configuration to each Greenplum Database segment host and restart the PXF server on each host.

